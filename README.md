# ISMIR-2023-Papers

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
![Version](https://img.shields.io/badge/version-v1.0.0-4FC528)
![GitHub repo size](https://img.shields.io/github/repo-size/yamathcy/ISMIR-2023-Papers)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://github.com/yamathcy/ISMIR-2023-Papers/blob/main/LICENSE)
[![Contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat)](https://github.com/yamathcy/ISMIR-2023-Papers/blob/main/README.md)
![GitHub contributors](https://img.shields.io/github/contributors/yamathcy/ISMIR-2023-Papers)
![GitHub commit activity (branch)](https://img.shields.io/github/commit-activity/t/yamathcy/ISMIR-2023-Papers)
![GitHub closed issues](https://img.shields.io/github/issues-closed/yamathcy/ISMIR-2023-Papers)
![GitHub issues](https://img.shields.io/github/issues/yamathcy/ISMIR-2023-Papers)
![GitHub closed pull requests](https://img.shields.io/github/issues-pr-closed/yamathcy/ISMIR-2023-Papers)
![GitHub pull requests](https://img.shields.io/github/issues-pr/yamathcy/ISMIR-2023-Papers)
![GitHub last commit](https://img.shields.io/github/last-commit/yamathcy/ISMIR-2023-Papers)
![GitHub watchers](https://img.shields.io/github/watchers/yamathcy/ISMIR-2023-Papers)
![GitHub forks](https://img.shields.io/github/forks/yamathcy/ISMIR-2023-Papers)
![GitHub Repo stars](https://img.shields.io/github/stars/yamathcy/ISMIR-2023-Papers)
![Visitors](https://api.visitorbadge.io/api/combined?path=https%3A%2F%2Fgithub.com%2Fyamathcy%2FISMIR-2023-Papers&label=Visitors&countColor=%23263759&style=flat)

<div style="float:left;">
  <img src="https://geps.dev/progress/100?successColor=006600" />
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/completed_checkmark_done.svg" width="25" />
</div>

---

ISMIR 2023 Papers: A complete collection of influential and exciting research papers from the [*ISMIR 2023*](https://ismir2023.ismir.net/) conference. Explore the latest advances in Music information retrieval. Code included. :star:

<p align="center">
    <a href="https://ismir2023.ismir.net/" target="_blank">
        <img width="600" src="https://cdn.jsdelivr.net/gh/DmitryRyumin/ISMIR-2023-Papers@main/images/ISMIR2023-banner.jpg" alt="ISMIR 2023">
    </a>
<p>

> :point_right: `*` This count includes repositories on GitHub, GitLab, Hugging Face, and distributions on PyPI, while excluding Web Page or GitHub Page links.

---

[*The PDF version of the ISMIR 2023 Conference Programme*](https://ismir2023.ismir.net/assets/img/detailed_schedule.pdf), comprises a list of all accepted full papers, their presentation order, as well as the designated presentation times.

---

<a href="https://github.com/DmitryRyumin/NewEraAI-Papers" style="float:left;">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arrow_click_cursor_pointer.png" width="25" />
  Other collections of the best AI conferences
</a>

<br />
<br />

> :exclamation: Conference table will be up to date all the time.

<table>
    <tr>
        <td><strong>Conference</strong></td>
        <td colspan="1" align="center"><strong>Year</strong></td>
    </tr>
    <tr>
      <td colspan="2" align="center"><i>Computer Vision (CV)</i></td>
    </tr>
    <tr>
        <td>CVPR</td>
        <td align="center"><a href="https://github.com/DmitryRyumin/CVPR-2023-Papers" target="_blank">2023</a></td>
    </tr>
    <tr>
        <td>ICCV</td>
        <td align="center"><a href="https://github.com/DmitryRyumin/ICCV-2023-Papers" target="_blank">2023</a></td>
    </tr>
    <tr>
      <td colspan="2" align="center"><i>Speech/Signal Processing (SP/SigProc)</i></td>
    </tr>
    <tr>
        <td>ICASSP</td>
        <td align="center"><a href="https://github.com/DmitryRyumin/ICASSP-2023-Papers" target="_blank">2023</a></td>
    </tr>
    <tr>
        <td>INTERSPEECH</td>
        <td align="center"><a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-Papers" target="_blank">2023</a></td>
    </tr>
</table>

---

## Contributors

<a href="https://github.com/yamathcy/ISMIR-2023-Papers/graphs/contributors">
  <img src="http://contributors.nn.ci/api?repo=yamathcy/ISMIR-2023-Papers" />
</a>

<br />
<br />

Contributions to improve the completeness of this list are greatly appreciated. If you come across any overlooked papers, please **feel free to [*create pull requests*](https://github.com/yamathcy/ISMIR-2023-Papers/pulls), [*open issues*](https://github.com/yamathcy/ISMIR-2023-Papers/issues) or contact me via [*email*](mailto:yyamamoto13044aa@gmail.com)**. Your participation is crucial to making this repository even better.

---

## [Papers](https://ismir2023.ismir.net/)

<!-- > :exclamation: Final paper links will be added post-conference. -->

<details open>
<summary>List of session<a id="sections"></a></summary>

- [Session 1](#session-1)
- [Session 2](#session-2)
- [Session 3](#session-3)
- [Session 4](#session-4)
- [Session 5](#session-5)
- [Session 6](#session-6)
- [Session 7](#session-7)

</details>

<!-- <a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a> -->

### Session 1

![Session Papers](https://img.shields.io/badge/Session%20Papers-16-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-7-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-11-1D7FBF)

| **Title** | **Repo** | **Paper** |
|-----------|:--------:|:---------:|
| Exploring the Correspondence of Melodic Contour with Gesture in Raga Alap Singing | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://dap-lab.github.io/audioGestureCorrespondence/) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://dap-lab.github.io/audioGestureCorrespondence/pdf/paper.pdf) |
| TriAD: Capturing Harmonics with 3D Convolutions | [![GitHub](https://img.shields.io/github/stars/migperfer/TriAD-ISMIR2023)](https://github.com/migperfer/TriAD-ISMIR2023) | :heavy_minus_sign: |
| Data Collection in Music Generation Training Sets: A Critical Analysis | [![GitHub](https://img.shields.io/github/stars/Sma1033/amgdatasetethics)](https://github.com/Sma1033/amgdatasetethics) | :heavy_minus_sign: |
| A Review of Validity and its Relationship to Music Information Research | [![GitHub](https://img.shields.io/github/stars/boblsturm/mirvaliditytutorial)](https://github.com/boblsturm/mirvaliditytutorial) | [![arXiv](https://img.shields.io/badge/arXiv-2301.01578-b31b1b.svg)](https://arxiv.org/abs/2301.01578) |
| Segmentation and Analysis of Taniavartanam in Carnatic Music Concerts | :heavy_minus_sign: | :heavy_minus_sign: |
| Transfer Learning and Bias Correction with Pre-Trained Audio Embeddings | [![GitHub](https://img.shields.io/github/stars/changhongw/audio-embedding-bias)](https://github.com/changhongw/audio-embedding-bias) | [![arXiv](https://img.shields.io/badge/arXiv-2307.10834-b31b1b.svg)](https://arxiv.org/abs/2307.10834) |
| Collaborative Song Dataset (CoSoD): An Annotated Dataset of Multi-Artist Collaborations in Popular Music | [![GitHub](https://img.shields.io/github/stars/duguay-michele/CoSoD)](https://github.com/duguay-michele/CoSoD) | [![arXiv](https://img.shields.io/badge/arXiv-2307.05588-b31b1b.svg)](https://arxiv.org/abs/2307.05588) |
| Human-AI Music Creation: Understanding the Perceptions and Experiences of Music Creators for Ethical and Productive Collaboration | [![GitHub](https://img.shields.io/github/stars/michelenewman/ISMIR23_supplemental_material)](https://github.com/michelenewman/ISMIR23_supplemental_material) | :heavy_minus_sign: |
| Impact of Time and Note Duration Tokenizations on Deep Learning Symbolic Music Modeling| [![GitHub](https://img.shields.io/github/stars/Natooz/music-modeling-time-duration)](https://github.com/Natooz/music-modeling-time-duration) | [![arXiv](https://img.shields.io/badge/arXiv-2310.08497-b31b1b.svg)](https://arxiv.org/abs/2310.08497) |
| Musical Micro-Timing for Live Coding | [![GitHub](https://img.shields.io/github/stars/MaxTheComputerer/sonicpi-metre)](https://github.com/MaxTheComputerer/sonicpi-metre) | :heavy_minus_sign: |
| A Few-Shot Neural Approach for Layout Analysis of Music Score Image | [![GitHub](https://img.shields.io/github/stars/fjcastellanos/FewShotLayoutAnalysisMusic)](https://github.com/fjcastellanos/FewShotLayoutAnalysisMusic) | :heavy_minus_sign: |
| TapTamDrum: A Dataset for Dualized Drum Patterns | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://taptamdrum.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/taptamdrum/dataset)](https://github.com/taptamdrum/dataset) | :heavy_minus_sign: |
| Real-Time Percussive Technique Recognition and Embedding Learning for the Acoustic Guitar | [![GitHub](https://img.shields.io/github/stars/iamtheband/martelloni_et_al_ismir2023)](https://github.com/iamtheband/martelloni_et_al_ismir2023) | [![arXiv](https://img.shields.io/badge/arXiv-2307.07426-b31b1b.svg)](https://arxiv.org/abs/2307.07426) |
| IteraTTA: An Interface for Exploring both Text Prompts and Audio Priors in Generating Music with Text-to-Audio Models | [![Demo](https://img.shields.io/badge/Demo-IteraTTA-FFD21F.svg)](https://iteratta.duckdns.org/) | [![arXiv](https://img.shields.io/badge/arXiv-2307.13005-b31b1b.svg)](https://arxiv.org/abs/2307.13005) |
| Similarity Evaluation of Violin Directivity Patterns for Musical Instrument Retrieval | :heavy_minus_sign: | :heavy_minus_sign: |
| Polyrhythmic Modelling of Non-Isochronous and Microtiming Patterns | :heavy_minus_sign: | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Session 2

| :id: | **Title** | **Repo** | **Paper** |
|------|-----------|:--------:|:---------:|
|2-1| CLaMP: Contrastive Language-Music Pre-training for Cross-Modal Symbolic Music Information Retrieval| [Github Pages](https://microsoft.github.io/muzic/clamp/) [Github](https://github.com/microsoft/muzic/tree/main/clamp)| |
|2-2| GENDER-CODED SOUND: ANALYSING THE GENDERING OF MUSIC IN TOY COMMERCIALS VIA MULTI-TASK LEARNING |[Github](https://github.com/marinelliluca/gender_coded_sound_ismir2023) ||
|2-3| A dataset and Baselines for Measuring and Predicting the Music Piece Memorability| [Github](https://github.com/anusfoil/SymRep)||
| 2-4 | Efficient Notation Assembly in Optical Music Recognition | - |  |
| 2-5 | White Box Search over Audio Synthesizer Parameters | - |  |
| 2-6 | Decoding drums, instrumentals, vocals, and mixed sources in music using human brain activity with fMRI | [Github](https://github.com/vkmcheung/neuromusic-decoding/) |  |
| 2-7 | Dual Attention-based Multi-scale Feature Fusion Approach for Dynamic Music Emotion Recognition | [Dataset](https://ismir-2023.github.io/MER1101/) |  |
| 2-8 | Automatic Piano Transcription with Hierarchical Frequency-Time Transformer | [Github](https://github.com/sony/hFT-Transformer) |  |
| 2-9 | High-Resolution Violin Transcription using Weak Labels | [Github](https://github.com/MTG/violin-transcription/) |  |
| 2-10 | Polyffusion: A Diffusion Model for Polyphonic Score Generation with Internal and External Controls | [Demo](https://polyffusion.github.io/) [Github](https://github.com/aik2mlj/polyffusion) |  |
| 2-11 | The Coordinated Corpus of Popular Musics (CoCoPops): A Meta-Dataset of Melodic and Harmonic Transcriptions | [Github](https://github.com/Computational-Cognitive-Musicology-Lab/CoCoPops) |  |
| 2-12 | Towards computational music analysis for music therapy | - |  |
| 2-13 | Timbre Transfer using Image-to-Image Denoising Diffusion Implicit Models | [Github](https://github.com/lucacoma/DiffTransfer) [Demo](https://lucacoma.github.io/DiffTransfer/)|  |
| 2-14 | Correlation of EEG responses reflects structural similarity of choruses in popular music | - |  |
| 2-15 | Chromatic Chords in Theory and Practice | [Github](https://github.com/MarkGotham/When-in-Rome) [Book](https://viva.pressbooks.pub/openmusictheory/chapter/anthology-harmony/) |  |
<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Session 3

| :id: | **Title** | **Repo** | **Paper** |
|------|-----------|:--------:|:---------:|
| 3-1 | BPS-Motif: A Dataset for Repeated Pattern Discovery of Polyphonic Symbolic Music |  |  |
| 3-2 | Weakly Supervised Multi-Pitch Estimation Using Cross-Version Alignment |  |  |
| 3-3 | The Batik-plays-Mozart Corpus: Linking Performance to Score to Musicological Annotations |  |  |
| 3-4 | Mono-to-stereo through parametric stereo generation |  |  |
| 3-5 | From West to East: Who can understand the music of the others better? |  |  |
| 3-6 | On the Performance of Optical Music Recognition in the Absence of Specific Training Data |  |  |
| 3-7 | Composer’s Assistant: An Interactive Transformer for Multi-Track MIDI Infilling |  |  |
| 3-8 | The FAV Corpus: An audio dataset of favorite pieces and excerpts, with formal analyses and music theory descriptors |  |  |
| 3-9 | LyricWhiz: Robust Multilingual Lyrics Transcription by Whispering to ChatGPT |  |  |
| 3-10 | Sounds out of place? Score independent detection of conspicuous mistake regions in MIDI piano performances |  |  |
| 3-11 | VampNet: Music Generation via Masked Acoustic Token Modeling |  |  |
| 3-12 | Expert and Novice Evaluations of Piano Performances: Criteria for Computer-Aided Feedback |  |  |
| 3-13 | Contrastive Learning for Cross-modal Artist Retrieval |  |  |
| 3-14 | Repetition-Structure Inference with Formal Prototypes |  |  |
| 3-15 | Algorithmic Harmonization of Tonal Melodies using Weighted Pitch Context Vectors |  |  |
| 3-16 | Text-to-lyrics generation with image-based semantics and reduced risk of plagiarism |  |  |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Session 4

| :id: | **Title** | **Repo** | **Paper** |
|------|-----------|:--------:|:---------:|
| 4-1 | LP-MusicCaps: LLM-Based Pseudo Music Captioning |  |  |
| 4-2 | A Repetition-based Triplet Mining Approach for Music Segmentation |  |  |
| 4-3 | Predicting Music Hierarchies with a Graph-Based Neural Decoder |  |  |
| 4-4 | Stabilizing Training with Soft Dynamic Time Warping: A Case Study for Pitch Class Estimation with Weakly Aligned Targets |  |  |
| 4-5 | Finding Tori: Self-supervised Learning for Analyzing Korean Folk Song |  |  |
| 4-6 | Singer Identity Representation Learning using Self-Supervised Techniques |  |  |
| 4-7 | On the effectiveness of speech self-supervised learning for music |  |  |
| 4-8 | Transformer-based beat tracking with low-resolution encoder and high-resolution decoder |  |  |
| 4-9 | Adding Descriptors to Melodies Improves Pattern Matching: A Study on Slovenian Folk Songs |  |  |
| 4-10 | How Control and Transparency for Users Could Improve Artist Fairness in Music Recommender Systems |  |  |
| 4-11 | Towards a New Interface for Music Listening: A User Experience Study on YouTube |  |  |
| 4-12 | FiloBass: A Dataset and Corpus Based Study of Jazz Basslines |  |  |
| 4-13 | Comparing Texture in Piano Scores |  |  |
| 4-14 | Introducing DiMCAT for processing and analyzing notated music on a very large scale |  |  |
| 4-15 | Sequence-to-Sequence Network Training Methods for Automatic Guitar Transcription with Tokenized Outputs |  |  |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Session 5

| :id: | **Title** | **Repo** | **Paper** |
|------|-----------|:--------:|:---------:|
| 5-1 | PESTO: Pitch Estimation with Self-supervised Transposition-equivariant Objective |  |  |
| 5-2 | The Games We Play: Exploring The Impact of ISMIR on Musicology |  |  |
| 5-3 | Carnatic Singing Voice Separation Using Cold Diffusion on Training Data with Bleeding |  |  |
| 5-4 | Unveiling the Impact of Musical Factors in Judging a Song on First Listen: Insights from a User Survey |  |  |
| 5-5 | Towards Building a Phylogeny of Gregorian Chant Melodies |  |  |
| 5-6 | Audio Embeddings as Teachers for Music Classification |  |  |
| 5-7 | ScorePerformer: Expressive Piano Performance Rendering with Fine-Grained Control |  |  |
| 5-8 | Roman Numeral Analysis with Graph Neural Networks: Onset-wise Predictions from Note-wise Features |  |  |
| 5-9 | Semi-Automated Music Catalog Curation Using Audio and Metadata |  |  |
| 5-10 | Crowd’s Performance on Temporal Activity Detection of Musical Instruments in Polyphonic Music |  |  |
| 5-11 | MoisesDB: A Dataset For Source Separation Beyond 4 Stems |  |  |
| 5-12 | Music as flow: a formal representation of hierarchical processes in music |  |  |
| 5-13 | Online Symbolic Music Alignment with Offline Reinforcement Learning |  |  |
| 5-14 | InverSinthII: Sound matching via self-supervised synthesizer-proxy and inference-time finetuning |  |  |
| 5-15 | A Semi-Supervised Deep Learning Approach to Dataset Collection for Query-by-Humming Task |  |  |
| 5-16 | Towards Improving Harmonic Sensitivity and Prediction Stability for Singing Melody Extraction |  |  |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Session 6

| :id: | **Title** | **Repo** | **Paper** |
|------|-----------|:--------:|:---------:|
| 6-1 | Singing Voice Synthesis using Differentiable LPC and Glottalflow Inspired Wavetables | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yoyololicon.github.io/golf-demo/) <br /> [![GitHub](https://img.shields.io/github/stars/yoyololicon/golf)](https://github.com/yoyololicon/golf) | [![arXiv](https://img.shields.io/badge/arXiv-2306.17252-b31b1b.svg)](https://arxiv.org/abs/2306.17252) |
| 6-2 | Harmonic Analysis with Neural Semi-CRF | :heavy_minus_sign: | :heavy_minus_sign: |
| 6-3 | A Dataset and Baseline for Automated Assessment of Timbre Quality in Trumpet Sound | [![GitHub](https://img.shields.io/github/stars/PNinad/ISMIR2023)](https://github.com/PNinad/ISMIR2023) <br /> [![Dataset](https://zenodo.org/badge/DOI/10.5281/zenodo.8132780.svg)](https://doi.org/10.5281/zenodo.8132780) | :heavy_minus_sign: |
| 6-4 | Visual Overviews for Sheet Music Structure | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.06140-b31b1b.svg)](https://arxiv.org/abs/2308.06140) |
| 6-5 | Passage Summarization with Recurrent Models for Audio – Sheet Music Retrieval | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2309.12111-b31b1b.svg)](https://arxiv.org/abs/2309.12111) |
| 6-6 | Predicting Performance Difficulty from Piano Sheet Music Images | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2309.16287-b31b1b.svg)](https://arxiv.org/abs/2309.16287) |
| 6-7 | Self-Refining of Pseudo Labels for Music Source Separation with Noisy Labeled Data | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2307.12576-b31b1b.svg)](https://arxiv.org/abs/2307.12576) |
| 6-8 | Quantifying the Ease of Playing Song Chords on the Guitar | :heavy_minus_sign: | :heavy_minus_sign: |
| 6-9 | FlexDTW: Dynamic Time Warping with Flexible Boundary Conditions | :heavy_minus_sign: | :heavy_minus_sign: |
| 6-10 | Modeling Bends in Popular Music Guitar Tablatures | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.12307-b31b1b.svg)](https://arxiv.org/abs/2308.12307) |
| 6-11 | Self-Similarity-based and Novelty-based Loss for Music Structure Analysis | [![GitHub](https://img.shields.io/github/stars/geoffroypeeters/ssmnet_ISMIR2023)](https://github.com/geoffroypeeters/ssmnet_ISMIR2023) | [![arXiv](https://img.shields.io/badge/arXiv-2309.02243-b31b1b.svg)](https://arxiv.org/abs/2309.02243) |
| 6-12 | Modeling Harmonic Similarity for Jazz using Cooccurrence Vectors and the Membrane Area | :heavy_minus_sign: | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://qmro.qmul.ac.uk/xmlui/bitstream/handle/123456789/90562/Bunks%20Modeling%20Harmonic%20Similarity%20for%20Jazz%20Using%20Co-occurrence%20Vectors%20and%20the%20Membrane%20Area%202023%20Accepted.pdf?sequence=2&isAllowed=n) |
| 6-13 | SingStyle111: A Multilingual Singing Dataset with Style Transfer | :heavy_minus_sign: | :heavy_minus_sign: |
| 6-14 | A Computational Evaluation Framework for Singable Lyric Translation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.13715-b31b1b.svg)](https://arxiv.org/abs/2308.13715) |
| 6-15 | Chorus-Playlist: Exploring the Impact of Listening to Only Choruses in a Playlist | :heavy_minus_sign: | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Session 7

| :id: | **Title** | **Repo** | **Paper** |
|------|-----------|:--------:|:---------:|
| 7-1 | Supporting Musicological Investigations with Information Retrieval Tools: An Iterative Approach to Data Collection | :heavy_minus_sign: | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://research.gold.ac.uk/id/eprint/34165/1/BitH_ISMIR_2023-camera-ready.pdf) |
| 7-2 | Optimizing Feature Extraction for Symbolic Music | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://musif.didone.eu/) <br /> [![GitHub](https://img.shields.io/github/stars/DIDONEproject/music_symbolic_features)](https://github.com/DIDONEproject/music_symbolic_features) | [![arXiv](https://img.shields.io/badge/arXiv-2307.05107-b31b1b.svg)](https://arxiv.org/abs/2307.05107) |
| 7-3 | Exploring Sampling Techniques for Generating Melodies with a Transformer Language Model | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.09454-b31b1b.svg)](https://arxiv.org/abs/2308.09454) |
| 7-4 | Measuring the Eurovision Song Contest: A Living Dataset for Real-World MIR | :heavy_minus_sign: | :heavy_minus_sign: |
| 7-5 | Efficient Supervised Training of Audio Transformers for Music Representation Learning | [![GitHub](https://img.shields.io/github/stars/palonso/MAEST)](https://github.com/palonso/MAEST) | [![arXiv](https://img.shields.io/badge/arXiv-2309.16418-b31b1b.svg)](https://arxiv.org/abs/2309.16418) |
| 7-6 | A Cross-Version Approach to Audio Representation Learning for Orchestral Music | [![GitHub](https://img.shields.io/github/stars/groupmm/cross_version_learning)](https://github.com/groupmm/cross_version_learning) | :heavy_minus_sign: |
| 7-7 | Music Source Separation with MLP Mixing of Time, Frequency, and Channel | :heavy_minus_sign: | :heavy_minus_sign: |
| 7-8 | Symbolic Music Representations for Classification Tasks: A Systematic Evaluation | [![GitHub](https://img.shields.io/github/stars/anusfoil/SymRep)](https://github.com/anusfoil/SymRep) | [![arXiv](https://img.shields.io/badge/arXiv-2309.02567-b31b1b.svg)](https://arxiv.org/abs/2309.02567) |
| 7-9 | The Music Meta Ontology: A Flexible Semantic Model for the Interoperability of Music Metadata | :heavy_minus_sign: | :heavy_minus_sign: |
| 7-10 | Polar Manhattan Displacement: Measuring Tonal Distances between Chords based on Intervallic Content | :heavy_minus_sign: | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://qmro.qmul.ac.uk/xmlui/bitstream/handle/123456789/89900/Pauwels%20Polar%20Manhattan%20Displacement%3a%20measuring%20tonal%20distances%20between%20chords%20based%20on%20intervallic%20content%202023%20Accepted.pdf?sequence=2&isAllowed=y) |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

### Late-Breaking Demo

> Will soon be added

---

## Star History

<p align="center">
    <a href="https://star-history.com/#yamathcy/ISMIR-2023-Papers&Date" target="_blank">
        <img width="500" src="https://api.star-history.com/svg?repos=yamathcy/ISMIR-2023-Papers&type=Date" alt="Star History Chart">
    </a>
<p>
